#!/usr/bin/env python
"""
Prepare Fine-Tuning Data

This script prepares and validates fine-tuning data generated by jon_data_generator.py
for use with the OpenAI fine-tuning API, and optionally starts a fine-tuning job.

Usage:
    python -m data_generation.prepare_fine_tuning --file path/to/data.jsonl
"""

import os
import sys
import json
import argparse
import random
from tqdm import tqdm

# Add src to path for imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from dotenv import load_dotenv
from openai import OpenAI

# Load environment variables
load_dotenv()

def validate_examples(examples):
    """Validate fine-tuning examples for format and content"""
    valid_examples = []
    invalid_examples = []
    
    for i, example in enumerate(examples):
        is_valid = True
        errors = []
        
        # Check for required format
        if not isinstance(example, dict):
            is_valid = False
            errors.append("Example is not a dictionary")
            continue
            
        if "messages" not in example:
            is_valid = False
            errors.append("Missing 'messages' field")
            continue
            
        messages = example["messages"]
        if not isinstance(messages, list):
            is_valid = False
            errors.append("'messages' is not a list")
            continue
            
        # Check message sequence (system -> user -> assistant)
        if len(messages) < 2:
            is_valid = False
            errors.append("Not enough messages (need at least 2)")
            
        if len(messages) >= 1 and messages[0]["role"] != "system":
            is_valid = False
            errors.append("First message must have role 'system'")
            
        if len(messages) >= 2 and messages[1]["role"] != "user":
            is_valid = False
            errors.append("Second message must have role 'user'")
            
        if len(messages) >= 3 and messages[2]["role"] != "assistant":
            is_valid = False
            errors.append("Third message must have role 'assistant'")
            
        # Check message formats
        for j, msg in enumerate(messages):
            if not isinstance(msg, dict):
                is_valid = False
                errors.append(f"Message {j} is not a dictionary")
                continue
                
            if "role" not in msg:
                is_valid = False
                errors.append(f"Message {j} missing 'role'")
                
            if "content" not in msg:
                is_valid = False
                errors.append(f"Message {j} missing 'content'")
                
            if "role" in msg and msg["role"] not in ["system", "user", "assistant"]:
                is_valid = False
                errors.append(f"Message {j} has invalid role: {msg['role']}")
                
            if "content" in msg and not isinstance(msg["content"], str):
                is_valid = False
                errors.append(f"Message {j} content is not a string")
                
            if "content" in msg and not msg["content"].strip():
                is_valid = False
                errors.append(f"Message {j} content is empty")
        
        # Record result
        if is_valid:
            valid_examples.append(example)
        else:
            invalid_examples.append((i, example, errors))
    
    return valid_examples, invalid_examples

def prepare_data(file_path, output_path, test_split=0.1, max_examples=None):
    """Prepare and validate fine-tuning data"""
    # Load data
    examples = []
    with open(file_path, 'r') as f:
        for line in f:
            try:
                example = json.loads(line.strip())
                examples.append(example)
            except json.JSONDecodeError:
                print(f"Warning: Could not parse line as JSON: {line[:50]}...")
    
    print(f"Loaded {len(examples)} examples from {file_path}")
    
    # Validate examples
    print("Validating examples...")
    valid_examples, invalid_examples = validate_examples(examples)
    
    print(f"Found {len(valid_examples)} valid examples")
    print(f"Found {len(invalid_examples)} invalid examples")
    
    if invalid_examples:
        print("\nSample invalid examples and errors:")
        for i, (idx, example, errors) in enumerate(invalid_examples[:5]):
            print(f"\nInvalid example {idx}:")
            print(f"Errors: {', '.join(errors)}")
            print(f"Example: {json.dumps(example, indent=2)[:200]}...")
    
    # Limit examples if needed
    if max_examples and len(valid_examples) > max_examples:
        print(f"Limiting to {max_examples} examples")
        valid_examples = valid_examples[:max_examples]
    
    # Split into training and test sets
    random.shuffle(valid_examples)
    split_idx = int(len(valid_examples) * (1 - test_split))
    
    train_examples = valid_examples[:split_idx]
    test_examples = valid_examples[split_idx:]
    
    print(f"Split into {len(train_examples)} training examples and {len(test_examples)} test examples")
    
    # Write output files
    train_output = output_path
    test_output = output_path.replace('.jsonl', '_test.jsonl')
    
    with open(train_output, 'w') as f:
        for example in train_examples:
            f.write(json.dumps(example) + '\n')
            
    with open(test_output, 'w') as f:
        for example in test_examples:
            f.write(json.dumps(example) + '\n')
            
    print(f"Wrote training data to {train_output}")
    print(f"Wrote test data to {test_output}")
    
    return train_output, test_output

def start_fine_tuning(training_file_path, model_name, suffix=None):
    """Start a fine-tuning job with OpenAI API"""
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    
    # Upload the training file
    print(f"Uploading training file: {training_file_path}")
    with open(training_file_path, "rb") as f:
        response = client.files.create(
            file=f,
            purpose="fine-tune"
        )
    file_id = response.id
    print(f"File uploaded with ID: {file_id}")
    
    # Create fine-tuning job
    suffix_param = {}
    if suffix:
        suffix_param["suffix"] = suffix
        
    print(f"Creating fine-tuning job with model: {model_name}")
    response = client.fine_tuning.jobs.create(
        training_file=file_id,
        model=model_name,
        **suffix_param
    )
    
    job_id = response.id
    print(f"Fine-tuning job created with ID: {job_id}")
    print(f"Status: {response.status}")
    print(f"You can monitor the job status with: openai api fine_tunes.get -i {job_id}")
    
    return job_id

def main():
    parser = argparse.ArgumentParser(description="Prepare fine-tuning data")
    parser.add_argument("--file", type=str, required=True,
                        help="Path to the JSONL file containing fine-tuning examples")
    parser.add_argument("--output", type=str, default=None,
                        help="Path for the processed output file (default: adds _processed to input)")
    parser.add_argument("--test-split", type=float, default=0.1,
                        help="Fraction of data to use for testing (0.0-1.0)")
    parser.add_argument("--max-examples", type=int, default=None,
                        help="Maximum number of examples to include")
    parser.add_argument("--fine-tune", action="store_true",
                        help="Start fine-tuning job after preparation")
    parser.add_argument("--model", type=str, default="gpt-3.5-turbo",
                        help="Base model to fine-tune (default: gpt-3.5-turbo)")
    parser.add_argument("--suffix", type=str, default=None,
                        help="Suffix for the fine-tuned model name")
    args = parser.parse_args()
    
    # Check if file exists
    if not os.path.exists(args.file):
        print(f"Error: File not found: {args.file}")
        sys.exit(1)
    
    # Set output path if not provided
    if not args.output:
        base, ext = os.path.splitext(args.file)
        args.output = f"{base}_processed{ext}"
    
    # Prepare and validate data
    train_file, test_file = prepare_data(
        args.file, 
        args.output,
        test_split=args.test_split,
        max_examples=args.max_examples
    )
    
    # Start fine-tuning if requested
    if args.fine_tune:
        if not os.environ.get("OPENAI_API_KEY"):
            print("Error: OPENAI_API_KEY environment variable not set")
            sys.exit(1)
            
        job_id = start_fine_tuning(train_file, args.model, args.suffix)
        
        # Write job info to file
        job_info = {
            "job_id": job_id,
            "base_model": args.model,
            "training_file": train_file,
            "test_file": test_file,
            "created_at": datetime.datetime.now().isoformat()
        }
        
        info_file = f"ft_job_{job_id[:8]}_info.json"
        with open(info_file, "w") as f:
            json.dump(job_info, f, indent=2)
            
        print(f"Job information saved to {info_file}")
    
if __name__ == "__main__":
    import datetime
    main() 