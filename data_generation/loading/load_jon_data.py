#!/usr/bin/env python
"""
Load Jon Data

This script loads the synthetic Jon data generated by jon_data_generator.py
into the vector store used by SchultzGPT.

Usage:
    python -m data_generation.load_jon_data --file path/to/data.jsonl
"""

import os
import sys
import json
import argparse
from tqdm import tqdm

# Add src to path for imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from dotenv import load_dotenv
from src.services.vector_store import VectorStore

# Load environment variables
load_dotenv()

def load_vector_data(file_path: str, vector_store: VectorStore) -> int:
    """Load data from a JSONL file into the vector store"""
    loaded_count = 0
    
    with open(file_path, 'r') as f:
        lines = f.readlines()
        
    for line in tqdm(lines, desc="Loading entries"):
        try:
            entry = json.loads(line.strip())
            
            # Extract fields
            if 'id' in entry and 'text' in entry and 'metadata' in entry:
                # Add to vector store
                vector_store.add_entry(
                    text=entry['text'],
                    metadata=entry['metadata'],
                    entry_id=entry['id']
                )
                loaded_count += 1
            else:
                print(f"Skipping entry: missing required fields - {entry}")
                
        except Exception as e:
            print(f"Error loading entry: {e}")
            
    # Save the vector store
    vector_store.save_store()
    
    return loaded_count

def main():
    parser = argparse.ArgumentParser(description="Load Jon data into vector store")
    parser.add_argument("--file", type=str, required=True,
                       help="Path to the JSONL file containing data to load")
    parser.add_argument("--store-dir", type=str, default=".vector_store",
                       help="Directory for the vector store")
    parser.add_argument("--dry-run", action="store_true",
                       help="Validate data without loading it")
    args = parser.parse_args()
    
    # Check if file exists
    if not os.path.exists(args.file):
        print(f"Error: File not found: {args.file}")
        sys.exit(1)
    
    # Initialize vector store
    vector_store = VectorStore(
        store_dir=args.store_dir,
        embedding_model=os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
    )
    
    # Get existing entry count
    existing_count = vector_store.get_stats().get('entry_count', 0)
    print(f"Vector store has {existing_count} existing entries")
    
    if args.dry_run:
        print("Dry run mode - validating data without loading")
        # Count valid entries in the file
        valid_count = 0
        with open(args.file, 'r') as f:
            for line in tqdm(f, desc="Validating entries"):
                try:
                    entry = json.loads(line.strip())
                    if 'id' in entry and 'text' in entry and 'metadata' in entry:
                        valid_count += 1
                except:
                    pass
        print(f"File contains {valid_count} valid entries that would be loaded")
    else:
        # Load data
        loaded_count = load_vector_data(args.file, vector_store)
        
        # Report results
        new_count = vector_store.get_stats().get('entry_count', 0)
        print(f"Successfully loaded {loaded_count} entries")
        print(f"Vector store now has {new_count} total entries")
    
if __name__ == "__main__":
    main() 